{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from numpy.linalg import norm\n",
    "from scipy import optimize\n",
    "from matplotlib.pyplot import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Pobranie danych z pliku Excel\n",
    "df = pd.read_excel('data_heart_disease.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Podział danych na część uczącą i testową (80:20)\n",
    "df_learn = df.iloc[:int(0.8*len(df)),:]\n",
    "df_test = df.iloc[int(0.8*len(df)):,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = np.array([df_learn.HighBP,df_learn.HighChol,df_learn.CholCheck,df_learn.BMI,df_learn.Smoker,df_learn.Stroke,df_learn.Diabetes,df_learn.PhysActivity,df_learn.Fruits,df_learn.Veggies,df_learn.HvyAlcoholConsump,df_learn.DiffWalk,df_learn.Sex,df_learn.Age]).transpose()\n",
    "\n",
    "df_learn_y = pd.DataFrame(df_learn.HeartDiseaseorAttack)\n",
    "y = np.array(df_learn_y)\n",
    "\n",
    "X = X/np.amax(X, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "test_X = np.array([df_test.HighBP,df_test.HighChol,df_test.CholCheck,df_test.BMI,df_test.Smoker,df_test.Stroke,df_test.Diabetes,df_test.PhysActivity,df_test.Fruits,df_test.Veggies,df_test.HvyAlcoholConsump,df_test.DiffWalk,df_test.Sex,df_test.Age]).transpose()\n",
    "\n",
    "df_test_y = pd.DataFrame(df_test.HeartDiseaseorAttack)\n",
    "test_y = np.array(df_test_y)\n",
    "\n",
    "test_X = test_X/np.amax(test_X, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "((202944, 14), (202944, 1))"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self, Lambda=0):\n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 14\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayer1Size = 6\n",
    "        self.hiddenLayer2Size = 6\n",
    "\n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayer1Size)\n",
    "        self.W2 = np.random.randn(self.hiddenLayer1Size, self.hiddenLayer2Size)\n",
    "        self.W3 = np.random.randn(self.hiddenLayer2Size, self.outputLayerSize)\n",
    "\n",
    "        #Regularization Parameter:\n",
    "        self.Lambda = Lambda\n",
    "\n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        self.a3 = self.sigmoid(self.z3)\n",
    "        self.z4 = np.dot(self.a3, self.W3)\n",
    "        yHat = self.sigmoid(self.z4)\n",
    "        return yHat\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "\n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)/X.shape[0] + (self.Lambda/2)*(np.sum(self.W1**2)+np.sum(self.W2**2))\n",
    "        return J\n",
    "\n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "\n",
    "        delta4 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z4))\n",
    "        #Add gradient of regularization term:\n",
    "        dJdW3 = np.dot(self.a3.T, delta4)/X.shape[0] + self.Lambda*self.W3\n",
    "\n",
    "        delta3 = np.dot(delta4, self.W3.T)*self.sigmoidPrime(self.z3)\n",
    "        dJdW2 = np.dot(X.T, delta3)/X.shape[0] + self.Lambda*self.W2\n",
    "\n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)/X.shape[0] + self.Lambda*self.W1\n",
    "\n",
    "        return dJdW1, dJdW2, dJdW3\n",
    "\n",
    "    #Helper functions for interacting with other methods/classes\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 Rolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel(), self.W3.ravel()))\n",
    "        return params\n",
    "\n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single parameter vector:\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayer1Size*self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end],\n",
    "                             (self.inputLayerSize, self.hiddenLayer1Size))\n",
    "        W2_end = W1_end + self.hiddenLayer1Size*self.hiddenLayer2Size\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end],\n",
    "                             (self.hiddenLayer1Size, self.hiddenLayer2Size))\n",
    "        W3_end = W2_end + self.hiddenLayer2Size*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W2_end:W3_end],\n",
    "                             (self.hiddenLayer2Size, self.outputLayerSize))\n",
    "\n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2, dJdW3 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel(), dJdW3.ravel()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "\n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))\n",
    "        self.testJ.append(self.N.costFunction(self.testX, self.testY))\n",
    "\n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "\n",
    "        return cost, grad\n",
    "\n",
    "    def train(self, trainX, trainY, testX, testY):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = trainX\n",
    "        self.y = trainY\n",
    "\n",
    "        self.testX = testX\n",
    "        self.testY = testY\n",
    "\n",
    "        #Make empty list to store training costs:\n",
    "        self.J = []\n",
    "        self.testJ = []\n",
    "\n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS',\n",
    "                                 args=(trainX, trainY), options=options, callback=self.callbackF)\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [],
   "source": [
    "T = trainer(NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.55836491],\n       [0.60435989],\n       [0.61614153],\n       ...,\n       [0.66757676],\n       [0.63792363],\n       [0.6359014 ]])"
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (202944,1) and (6,1) not aligned: 1 (dim 1) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [246]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_y\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [241]\u001B[0m, in \u001B[0;36mtrainer.train\u001B[1;34m(self, trainX, trainY, testX, testY)\u001B[0m\n\u001B[0;32m     30\u001B[0m params0 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mN\u001B[38;5;241m.\u001B[39mgetParams()\n\u001B[0;32m     32\u001B[0m options \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaxiter\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m200\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdisp\u001B[39m\u001B[38;5;124m'\u001B[39m : \u001B[38;5;28;01mTrue\u001B[39;00m}\n\u001B[1;32m---> 33\u001B[0m _res \u001B[38;5;241m=\u001B[39m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcostFunctionWrapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBFGS\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m                         \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrainX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrainY\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbackF\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mN\u001B[38;5;241m.\u001B[39msetParams(_res\u001B[38;5;241m.\u001B[39mx)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizationResults \u001B[38;5;241m=\u001B[39m _res\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_minimize.py:676\u001B[0m, in \u001B[0;36mminimize\u001B[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[0;32m    674\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_cg(fun, x0, args, jac, callback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    675\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbfgs\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 676\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_bfgs(fun, x0, args, jac, callback, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[0;32m    677\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnewton-cg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    678\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[0;32m    679\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1296\u001B[0m, in \u001B[0;36m_minimize_bfgs\u001B[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[0;32m   1293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m maxiter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1294\u001B[0m     maxiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(x0) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m200\u001B[39m\n\u001B[1;32m-> 1296\u001B[0m sf \u001B[38;5;241m=\u001B[39m \u001B[43m_prepare_scalar_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1297\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mfinite_diff_rel_step\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfinite_diff_rel_step\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1299\u001B[0m f \u001B[38;5;241m=\u001B[39m sf\u001B[38;5;241m.\u001B[39mfun\n\u001B[0;32m   1300\u001B[0m myfprime \u001B[38;5;241m=\u001B[39m sf\u001B[38;5;241m.\u001B[39mgrad\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:263\u001B[0m, in \u001B[0;36m_prepare_scalar_function\u001B[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001B[0m\n\u001B[0;32m    259\u001B[0m     bounds \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39minf, np\u001B[38;5;241m.\u001B[39minf)\n\u001B[0;32m    261\u001B[0m \u001B[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001B[39;00m\n\u001B[0;32m    262\u001B[0m \u001B[38;5;66;03m# calculation reduces overall function evaluations.\u001B[39;00m\n\u001B[1;32m--> 263\u001B[0m sf \u001B[38;5;241m=\u001B[39m \u001B[43mScalarFunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mfinite_diff_rel_step\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sf\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001B[0m, in \u001B[0;36mScalarFunction.__init__\u001B[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m fun_wrapped(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_fun_impl \u001B[38;5;241m=\u001B[39m update_fun\n\u001B[1;32m--> 158\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# Gradient evaluation\u001B[39;00m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(grad):\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[1;32m--> 251\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[1;34m()\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[1;32m--> 155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mfun_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    134\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001B[39;00m\n\u001B[1;32m---> 76\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[1;32mc:\\users\\pawki\\pycharmprojects\\siec_neuronowa\\venv\\lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[1;34m(self, x, *args)\u001B[0m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m---> 70\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "Input \u001B[1;32mIn [241]\u001B[0m, in \u001B[0;36mtrainer.costFunctionWrapper\u001B[1;34m(self, params, X, y)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcostFunctionWrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, params, X, y):\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mN\u001B[38;5;241m.\u001B[39msetParams(params)\n\u001B[1;32m---> 13\u001B[0m     cost \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcostFunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mN\u001B[38;5;241m.\u001B[39mcomputeGradients(X,y)\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cost, grad\n",
      "Input \u001B[1;32mIn [240]\u001B[0m, in \u001B[0;36mNeural_Network.costFunction\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcostFunction\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;66;03m#Compute cost for given X,y, use weights already stored in class.\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39myHat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m     J \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.5\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28msum\u001B[39m((y\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39myHat)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m/\u001B[39mX\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLambda\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m*\u001B[39m(np\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW1\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m+\u001B[39mnp\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW2\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m))\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m J\n",
      "Input \u001B[1;32mIn [240]\u001B[0m, in \u001B[0;36mNeural_Network.forward\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz3 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma2, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW2)\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ma3 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz3)\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz4 \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ma3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mW3\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m yHat \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mz4)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m yHat\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: shapes (202944,1) and (6,1) not aligned: 1 (dim 1) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "T.train(X,y, test_X, test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.10330492],\n       [0.08934011],\n       [0.09882956],\n       ...,\n       [0.08325951],\n       [0.08228962],\n       [0.08217452]])"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]])"
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'Cost')"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(T.J)\n",
    "grid(1)\n",
    "xlabel('Iterations')\n",
    "ylabel('Cost')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}