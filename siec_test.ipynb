{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from numpy.linalg import norm\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Pobranie danych z pliku Excel\n",
    "df = pd.read_excel('data_heart_disease.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Podział danych na część uczącą i testową (80:20)\n",
    "df_learn = df.iloc[:int(0.7*len(df)),:]\n",
    "df_test = df.iloc[int(0.7*len(df)):,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X = np.array([df_learn.HighBP,df_learn.HighChol,df_learn.CholCheck,df_learn.BMI,df_learn.Smoker,df_learn.Stroke,df_learn.Diabetes,df_learn.PhysActivity,df_learn.Fruits,df_learn.Veggies,df_learn.HvyAlcoholConsump,df_learn.DiffWalk,df_learn.Sex,df_learn.Age]).transpose()\n",
    "\n",
    "df_learn_y = df_learn.HeartDiseaseorAttack\n",
    "y = np.array([df_learn_y]).transpose()\n",
    "\n",
    "X = X/np.amax(X, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "((177576, 14), (177576, 1))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Neural_Network(object):\n",
    "    def __init__(self):\n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 14\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayer1Size = 6\n",
    "        self.hiddenLayer2Size = 6\n",
    "\n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayer1Size)\n",
    "        self.W2 = np.random.randn(self.hiddenLayer1Size, self.hiddenLayer2Size)\n",
    "        self.W3 = np.random.randn(self.hiddenLayer2Size, self.outputLayerSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        #Propagate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        self.a3 = self.sigmoid(self.z3)\n",
    "        self.z4 = np.dot(self.a3, self.W3)\n",
    "        yHat = self.sigmoid(self.z4)\n",
    "        return yHat\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "\n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "\n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "\n",
    "        delta4 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z4))\n",
    "        dJdW3 = np.dot(self.a3.T, delta4)\n",
    "\n",
    "        delta3 = np.dot(delta4, self.W3.T)*self.sigmoidPrime(self.z3)\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "\n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)\n",
    "\n",
    "        return dJdW1, dJdW2, dJdW3\n",
    "\n",
    "     #Helper Functions for interacting with other classes:\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 unrolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel(), self.W3.ravel()))\n",
    "        return params\n",
    "\n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single paramater vector.\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayer1Size * self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayer1Size))\n",
    "        W2_end = W1_end + self.hiddenLayer1Size*self.hiddenLayer2Size\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayer1Size, self.hiddenLayer2Size))\n",
    "        W3_end = W2_end + self.hiddenLayer2Size*self.outputLayerSize\n",
    "        self.W3 = np.reshape(params[W2_end:W3_end], (self.hiddenLayer2Size, self.outputLayerSize))\n",
    "\n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2, dJdW3 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel(), dJdW3.ravel()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "## Do testu definicji obliczającej gradient z góry - potencjalnie do usunięcia\n",
    "\n",
    "def computeNumericalGradient(N, X, y):\n",
    "        paramsInitial = N.getParams()\n",
    "        numgrad = np.zeros(paramsInitial.shape)\n",
    "        perturb = np.zeros(paramsInitial.shape)\n",
    "        e = 1e-4\n",
    "\n",
    "        for p in range(len(paramsInitial)):\n",
    "            #Set perturbation vector\n",
    "            perturb[p] = e\n",
    "            N.setParams(paramsInitial + perturb)\n",
    "            loss2 = N.costFunction(X, y)\n",
    "\n",
    "            N.setParams(paramsInitial - perturb)\n",
    "            loss1 = N.costFunction(X, y)\n",
    "\n",
    "            #Compute Numerical Gradient\n",
    "            numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "\n",
    "            #Return the value we changed to zero:\n",
    "            perturb[p] = 0\n",
    "\n",
    "        #Return Params to original value:\n",
    "        N.setParams(paramsInitial)\n",
    "\n",
    "        return numgrad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "\n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))\n",
    "\n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "\n",
    "        return cost, grad\n",
    "\n",
    "    def train(self, X, y):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        #Make empty list to store costs:\n",
    "        self.J = []\n",
    "\n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 3000, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS',\n",
    "                                 args=(X, y), options=options, callback=self.callbackF)\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "NN = Neural_Network()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "T = trainer(NN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:30: RuntimeWarning: overflow encountered in square\n",
      "  return np.exp(-z)/((1+np.exp(-z))**2)\n",
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:26: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n",
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-z)/((1+np.exp(-z))**2)\n",
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(-z)/((1+np.exp(-z))**2)\n",
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:26: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n",
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-z)/((1+np.exp(-z))**2)\n",
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:30: RuntimeWarning: overflow encountered in square\n",
      "  return np.exp(-z)/((1+np.exp(-z))**2)\n",
      "C:\\Users\\pawki\\AppData\\Local\\Temp\\ipykernel_24156\\2840466036.py:30: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(-z)/((1+np.exp(-z))**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 6311.922811\n",
      "         Iterations: 953\n",
      "         Function evaluations: 1021\n",
      "         Gradient evaluations: 1010\n"
     ]
    }
   ],
   "source": [
    "T.train(X,y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.20604013],\n       [0.0122487 ],\n       [0.18462831],\n       ...,\n       [0.0548891 ],\n       [0.05313525],\n       [0.04211262]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.forward(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}